{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a5b9dd",
   "metadata": {},
   "source": [
    "#### 1. Cite 5 diferenças entre o RandomForest e o AdaBoost <br>\n",
    "\n",
    "#### 2.Acesse o link Scikit-learn–adaboost, leia a explicação (traduza se for preciso) e crie um jupyternotebook contendo o exemplo do AdaBoost. <br>\n",
    "\n",
    "#### 3. Cite 5 Hyperparametrosimportantes no AdaBoost. <br>\n",
    "\n",
    "#### 4. (Opcional) Utilize o GridSearchpara encontrar os melhores hyperparametrospara o conjunto de dados do exemplo (load_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998b70",
   "metadata": {},
   "source": [
    "#### 1 - Cite 5 diferenças entre o RandomForest e o AdaBoost <br><br>\n",
    "#### Diferença 1 - Tamanho/Profundidade: \n",
    "O RandomForest cria N modelos que trabalham independentemente, precisa que seus hyperparametros sejam alterados para alterar a sua profundidade, número de folhas, etc...\n",
    "\n",
    "O AdaBoost cria árvores igual ao número de features(colunas explicativas), porém essa árvore vai conter apenas a raiz e duas folhas, nada mais.\n",
    "\n",
    "#### <br>Diferença 2 - Peso das conclusões: \n",
    "Random Forest tem seus modelos treinados em paralelo e sua decisão vai ser tomada com a média das respostas.\n",
    "\n",
    "O AdaBoost vai fazer N loopings e para cada rodada vai ser escolhido o modelo com melhores resultados, sua conclusão final vai ser baseada em todos modelos, porém os modelos que acertaram mais vão ter um peso maior.\n",
    "\n",
    "#### <br>Diferença 3 - Treinamento: \n",
    "O Random Forest treina seus modelos em paralelo com uma aleatoriedade na etapa do bootstrap e no número de features para criação da árvore.\n",
    "\n",
    "No caso do AdaBoost, os modelos são treinados sequencialmente, cada modelo novo é criado baseado no anterior, sendo o modelo anterior com melhor resultado e o bootstrap é feito dando maior peso nas linhas onde tiveram erro.\n",
    "\n",
    "#### <br>Diferença 4 - Outliers:\n",
    "O RandomForest usa vários modelos diferentes e seu bootstrap é aleatório, dificultado um resultado baseado em outliers.\n",
    "\n",
    "O AdaBoost vai ter seu bootstrap sempre com base nos erros anteriores, se o erro foi baseado em um outlier isso pode ser prejudicial para a conclusão final.\n",
    "\n",
    "#### <br> Diferença 5 - Paralelização:\n",
    "Como o RandomForest tem sua conclusão baseada na união de modelos independentes, então sua conclusão pode ser tirada de modelos criados em núcleos diferentes ou até em máquinas diferentes. \n",
    "\n",
    "Já o AdaBoost, sempre depende do resultado anterior, o que deixa muito inviável uma paralelização. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d63bb5",
   "metadata": {},
   "source": [
    "#### 2.Acesse o link Scikit-learn–adaboost, leia a explicação (traduza se for preciso) e crie um jupyternotebook contendo o exemplo do AdaBoost. <br>\n",
    "https://scikit-learn.org/stable/modules/ensemble.html#adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fb02a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35eb3060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466666666666665"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd117c0",
   "metadata": {},
   "source": [
    "#### 3. Cite 5 Hyperparametrosimportantes no AdaBoost. <br>\n",
    "\n",
    "n_estimator - Estima quantas stumps(os modelos com raiz e duas folhas) vão ser usadas para treinar.\n",
    "\n",
    "learning_rate - Altera o peso dado para as linhas no novo bootstrap, pesos menores geralmente precisam de mais stumps porém tem um resultado final mais robusto.\n",
    "\n",
    "base_estimator - O padrão do AdaBoost é uma árvore com um nó e duas folhas, porém o base_estimator pode ser usado para declarar outros modelos como uma árvore de decisão completa.\n",
    "\n",
    "base_estimator_max_depth - Se o modelo usado no base_estimator for uma árvore de decisão, sua profundidade máxima pode ser alterada pelo base_estimator_max_depth.\n",
    "\n",
    "base_estimator_criterion - Define qual o critério de divisão para criação da árvore, gini, entropia..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744808b",
   "metadata": {},
   "source": [
    "#### 4. (Opcional) Utilize o GridSearchpara encontrar os melhores hyperparametrospara o conjunto de dados do exemplo (load_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de1d9fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hyperparametros: {'learning_rate': 1.0, 'n_estimators': 100}\n",
      "\n",
      "Melhor pontuação média: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Carregando os dados\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "#Criando o classificador AdaBoost\n",
    "clf = AdaBoostClassifier()\n",
    "\n",
    "# Hyperparametros a serem alterados\n",
    "# 50, 100 e 150 stumps e 1%, 10%, 100%\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 1.0],\n",
    "}\n",
    "\n",
    "# Criando o grid com o classificador clf, os hyperparametros param_grid e 3 folders(subconjuntos temporarios para tomada de decisão randomica)\n",
    "grids = GridSearchCV(clf, param_grid, cv = 3)\n",
    "\n",
    "# Treinando o modelo\n",
    "grids.fit(X, y)\n",
    "\n",
    "# Melhores hyperparametros da lista param_grid\n",
    "print('Melhores hyperparametros:', grids.best_params_)\n",
    "print('\\nMelhor pontuação média:', grids.best_score_)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
